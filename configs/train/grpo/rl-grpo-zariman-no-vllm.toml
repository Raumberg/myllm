[model]
model_name_or_path = "attn-signs/Zariman-R-7b-v0"

[datasets]
dataset = "d0rj/gsm8k-ru"
problem_field = "question"
solution_field = "answer"
dataloader_num_workers = 2
test_size = 0.1

[run]
run_name = "rl-zariman-7"
report_to = "wandb"
logging_first_step = true
logging_steps = 1
output_dir = "models/attn-signs-zariman-7"
project_name = "rl-zariman"

[training]
num_train_epochs = 1
learning_rate = 0.00005
bf16 = true
seed = 42
use_peft = true

[grpo]

[lora]
lora_target_modules = [
    "k_proj",
    "v_proj",
    "q_proj",
    "o_proj",
    "gate_proj",
    "up_proj",
    "down_proj",
]
lora_r = 32
lora_alpha = 64

[fusion]
use_liger = true

[tokenizer]
system_prompt = "Ты полезный ассистент. Отвечай на вопросы, сохраняя следующую структуру: <Thought> Твои мысли и рассуждения </Thought> <output> Твой конечный ответ </output>"
assistant_message_template =  "<|im_start|>assistant<|im_sep|>"
pad_token =  "<|endoftext|>"
eos_token =  "<|im_end|>"
chat_template = "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|im_start|>' + message['role'] + '<|im_sep|>'+ message['content'] | trim + '<|im_end|>' %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant<|im_sep|>' }}{% endif %}"
force_chat_template =  true
added_special_tokens =  ["<|im_sep|>"]